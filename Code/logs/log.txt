****************************************************************************************************
[%]GPU Enabled
===============================================Features===============================================
Prediction = height, Environment = tennis
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'intr_x-6', 'intr_y-7', 'intr_z-8', 'ray_x-9', 'ray_y-10', 'ray_z-11', 'eot-12', 'cd-13', 'og-14', 'hw-15', 'rad-16', 'f_sin-17', 'f_cos-18', 'fx-19', 'fy-20', 'fz-21', 'fx_norm-22', 'fy_norm-23', 'fz_norm-24', 'intrinsic-25', 'extrinsic-26', 'azimuth-27', 'elevation-28', 'extrinsic_inv-29', 'g-30']
Selected features :  No features cols from real data
1. input_col =  [u, v]
2. gt_col =  [x, y, z] (if existed)
====================================================================================================
[#]Testing : Trajectory Estimation
===============================Dataset shape===============================
Mixed : (118,)
===========================================================================
===>Load ckpt with Optimizer state, Decay and Scheduler state
[#] Loading ... ../model_checkpoints//CVPR_Week6_finalize_method/ihv_net_cat_h_bw_agg_tennis/ihv_net_cat_h_bw_agg_tennis_best_traj_ma.pth
====================================================================================================
[#] Model Parameters
===>  rnn.h torch.Size([3, 2, 1, 64])
===>  rnn.c torch.Size([3, 2, 1, 64])
===>  rnn.ls.0.weight_ih_l0 torch.Size([256, 4])
===>  rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
===>  rnn.ls.0.bias_ih_l0 torch.Size([256])
===>  rnn.ls.0.bias_hh_l0 torch.Size([256])
===>  rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 4])
===>  rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
===>  rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
===>  rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
===>  rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
===>  rnn.ls.1.bias_ih_l0 torch.Size([256])
===>  rnn.ls.1.bias_hh_l0 torch.Size([256])
===>  rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
===>  rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
===>  rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
===>  rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
===>  rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
===>  rnn.ls.2.bias_ih_l0 torch.Size([256])
===>  rnn.ls.2.bias_hh_l0 torch.Size([256])
===>  rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
===>  rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
===>  rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
===>  mlp.seq1.0.weight torch.Size([32, 128])
===>  mlp.seq1.0.bias torch.Size([32])
===>  mlp.seq1.2.weight torch.Size([32, 32])
===>  mlp.seq1.2.bias torch.Size([32])
===>  mlp.seq1.4.weight torch.Size([32, 32])
===>  mlp.seq1.4.bias torch.Size([32])
===>  mlp.seq1.6.weight torch.Size([1, 32])
===>  mlp.seq1.6.bias torch.Size([1])
===>  rnn.hs torch.Size([3, 2, 1, 64])
===>  rnn.cs torch.Size([3, 2, 1, 64])
===>  rnn.ls_fw.0.weight_ih torch.Size([256, 6])
===>  rnn.ls_fw.0.weight_hh torch.Size([256, 64])
===>  rnn.ls_fw.0.bias_ih torch.Size([256])
===>  rnn.ls_fw.0.bias_hh torch.Size([256])
===>  rnn.ls_fw.1.weight_ih torch.Size([256, 64])
===>  rnn.ls_fw.1.weight_hh torch.Size([256, 64])
===>  rnn.ls_fw.1.bias_ih torch.Size([256])
===>  rnn.ls_fw.1.bias_hh torch.Size([256])
===>  rnn.ls_fw.2.weight_ih torch.Size([256, 64])
===>  rnn.ls_fw.2.weight_hh torch.Size([256, 64])
===>  rnn.ls_fw.2.bias_ih torch.Size([256])
===>  rnn.ls_fw.2.bias_hh torch.Size([256])
===>  rnn.ls_bw.0.weight_ih torch.Size([256, 6])
===>  rnn.ls_bw.0.weight_hh torch.Size([256, 64])
===>  rnn.ls_bw.0.bias_ih torch.Size([256])
===>  rnn.ls_bw.0.bias_hh torch.Size([256])
===>  rnn.ls_bw.1.weight_ih torch.Size([256, 64])
===>  rnn.ls_bw.1.weight_hh torch.Size([256, 64])
===>  rnn.ls_bw.1.bias_ih torch.Size([256])
===>  rnn.ls_bw.1.bias_hh torch.Size([256])
===>  rnn.ls_bw.2.weight_ih torch.Size([256, 64])
===>  rnn.ls_bw.2.weight_hh torch.Size([256, 64])
===>  rnn.ls_bw.2.bias_ih torch.Size([256])
===>  rnn.ls_bw.2.bias_hh torch.Size([256])
===>  rnn.mlp_fw.seq1.0.weight torch.Size([32, 64])
===>  rnn.mlp_fw.seq1.0.bias torch.Size([32])
===>  rnn.mlp_fw.seq1.2.weight torch.Size([32, 32])
===>  rnn.mlp_fw.seq1.2.bias torch.Size([32])
===>  rnn.mlp_fw.seq1.4.weight torch.Size([32, 32])
===>  rnn.mlp_fw.seq1.4.bias torch.Size([32])
===>  rnn.mlp_fw.seq1.6.weight torch.Size([1, 32])
===>  rnn.mlp_fw.seq1.6.bias torch.Size([1])
===>  rnn.mlp_bw.seq1.0.weight torch.Size([32, 64])
===>  rnn.mlp_bw.seq1.0.bias torch.Size([32])
===>  rnn.mlp_bw.seq1.2.weight torch.Size([32, 32])
===>  rnn.mlp_bw.seq1.2.bias torch.Size([32])
===>  rnn.mlp_bw.seq1.4.weight torch.Size([32, 32])
===>  rnn.mlp_bw.seq1.4.bias torch.Size([32])
===>  rnn.mlp_bw.seq1.6.weight torch.Size([1, 32])
===>  rnn.mlp_bw.seq1.6.bias torch.Size([1])
===>  rnn2.h torch.Size([3, 2, 1, 64])
===>  rnn2.c torch.Size([3, 2, 1, 64])
===>  rnn2.ls.0.weight_ih_l0 torch.Size([256, 5])
===>  rnn2.ls.0.weight_hh_l0 torch.Size([256, 64])
===>  rnn2.ls.0.bias_ih_l0 torch.Size([256])
===>  rnn2.ls.0.bias_hh_l0 torch.Size([256])
===>  rnn2.ls.0.weight_ih_l0_reverse torch.Size([256, 5])
===>  rnn2.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn2.ls.0.bias_ih_l0_reverse torch.Size([256])
===>  rnn2.ls.0.bias_hh_l0_reverse torch.Size([256])
===>  rnn2.ls.1.weight_ih_l0 torch.Size([256, 128])
===>  rnn2.ls.1.weight_hh_l0 torch.Size([256, 64])
===>  rnn2.ls.1.bias_ih_l0 torch.Size([256])
===>  rnn2.ls.1.bias_hh_l0 torch.Size([256])
===>  rnn2.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
===>  rnn2.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn2.ls.1.bias_ih_l0_reverse torch.Size([256])
===>  rnn2.ls.1.bias_hh_l0_reverse torch.Size([256])
===>  rnn2.ls.2.weight_ih_l0 torch.Size([256, 128])
===>  rnn2.ls.2.weight_hh_l0 torch.Size([256, 64])
===>  rnn2.ls.2.bias_ih_l0 torch.Size([256])
===>  rnn2.ls.2.bias_hh_l0 torch.Size([256])
===>  rnn2.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
===>  rnn2.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn2.ls.2.bias_ih_l0_reverse torch.Size([256])
===>  rnn2.ls.2.bias_hh_l0_reverse torch.Size([256])
===>  mlp.seq1.0.weight torch.Size([32, 128])
===>  mlp.seq1.0.bias torch.Size([32])
===>  mlp.seq1.2.weight torch.Size([32, 32])
===>  mlp.seq1.2.bias torch.Size([32])
===>  mlp.seq1.4.weight torch.Size([32, 32])
===>  mlp.seq1.4.bias torch.Size([32])
===>  mlp.seq1.6.weight torch.Size([1, 32])
===>  mlp.seq1.6.bias torch.Size([1])
===>  rnn.h torch.Size([3, 2, 1, 64])
===>  rnn.c torch.Size([3, 2, 1, 64])
===>  rnn.ls.0.weight_ih_l0 torch.Size([256, 5])
===>  rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
===>  rnn.ls.0.bias_ih_l0 torch.Size([256])
===>  rnn.ls.0.bias_hh_l0 torch.Size([256])
===>  rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 5])
===>  rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
===>  rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
===>  rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
===>  rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
===>  rnn.ls.1.bias_ih_l0 torch.Size([256])
===>  rnn.ls.1.bias_hh_l0 torch.Size([256])
===>  rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
===>  rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
===>  rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
===>  rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
===>  rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
===>  rnn.ls.2.bias_ih_l0 torch.Size([256])
===>  rnn.ls.2.bias_hh_l0 torch.Size([256])
===>  rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
===>  rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
===>  rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
===>  rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
===>  mlp.seq1.0.weight torch.Size([32, 128])
===>  mlp.seq1.0.bias torch.Size([32])
===>  mlp.seq1.2.weight torch.Size([32, 32])
===>  mlp.seq1.2.bias torch.Size([32])
===>  mlp.seq1.4.weight torch.Size([32, 32])
===>  mlp.seq1.4.bias torch.Size([32])
===>  mlp.seq1.6.weight torch.Size([1, 32])
===>  mlp.seq1.6.bias torch.Size([1])
====================================================================================================
[#] Found the ckpt ===> ../model_checkpoints//CVPR_Week6_finalize_method/ihv_net_cat_h_bw_agg_tennis/ihv_net_cat_h_bw_agg_tennis_best_traj_ma.pth
Module ===> flag.....Loaded!!!
Module ===> height.....Loaded!!!
Module ===> refinement.....Loaded!!!
[#]Model Architecture
####### Model - flag #######
Flag_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(4, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
  (sigmoid): Sigmoid()
)
####### Model - height #######
Height_Module_Agg(
  (rnn): LSTM_Agg(
    (ls_fw): Sequential(
      (0): LSTMCell(6, 64)
      (1): LSTMCell(64, 64)
      (2): LSTMCell(64, 64)
    )
    (ls_bw): Sequential(
      (0): LSTMCell(6, 64)
      (1): LSTMCell(64, 64)
      (2): LSTMCell(64, 64)
    )
    (mlp_fw): Vanilla_MLP(
      (activation): LeakyReLU(negative_slope=0.01)
      (seq1): Sequential(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=32, out_features=32, bias=True)
        (3): LeakyReLU(negative_slope=0.01)
        (4): Linear(in_features=32, out_features=32, bias=True)
        (5): LeakyReLU(negative_slope=0.01)
        (6): Linear(in_features=32, out_features=1, bias=True)
      )
    )
    (mlp_bw): Vanilla_MLP(
      (activation): LeakyReLU(negative_slope=0.01)
      (seq1): Sequential(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=32, out_features=32, bias=True)
        (3): LeakyReLU(negative_slope=0.01)
        (4): Linear(in_features=32, out_features=32, bias=True)
        (5): LeakyReLU(negative_slope=0.01)
        (6): Linear(in_features=32, out_features=1, bias=True)
      )
    )
  )
  (rnn2): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(5, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
)
####### Model - refinement #######
Refinement_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(5, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
)
[#]Batch-0
****************************************************************************************************
[#]Evaluation Results : "CVPR_Week6_finalize_method/ihv_net_cat_h_bw_agg_tennis"
[#]Data : "../../Public_dataset/Dataset/TrackNet1_Dataset/prep_npy_finale/"
****************************************************************************************************
Space :  xyz
===> Distance :  MAE
	MEAN :  [1.8301 0.5621 5.8592]
	SD :  [1.1638 0.3876 3.9617]
===> Distance :  MSE
	MEAN :  [ 4.7039  0.4662 50.0253]
	SD :  [ 5.0335  0.5826 58.3718]
===> Distance :  RMSE
	RMSE :  [2.1688 0.6828 7.0729]
===> Distance :  RMSE-DISTANCE
	RMSE-DISTANCE-1 :  6.363088
	RMSE-DISTANCE-2 :  7.4293675
****************************************************************************************************
Space :  xyz_refined
===> Distance :  MAE
	MEAN :  [1.8312 0.5619 5.8645]
	SD :  [1.1638 0.3874 3.9577]
===> Distance :  MSE
	MEAN :  [ 4.7078  0.4658 50.056 ]
	SD :  [ 5.0324  0.5862 58.2872]
===> Distance :  RMSE
	RMSE :  [2.1698 0.6825 7.075 ]
===> Distance :  RMSE-DISTANCE
	RMSE-DISTANCE-1 :  6.366621
	RMSE-DISTANCE-2 :  7.4316626
****************************************************************************************************
[#] Runtime : 1.8798010349273682+-0.0
[#] Saving reconstruction to ../reconstructed/Tennis_week6_finalize_method//tags_CVPR_Week6_finalize_method/ihv_net_cat_h_bw_agg_tennis
[#] Done
