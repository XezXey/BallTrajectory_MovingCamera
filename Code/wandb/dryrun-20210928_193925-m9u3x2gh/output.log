===============================================Features===============================================
Prediction = height, Environment = unity
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'intr_x-6', 'intr_y-7', 'intr_z-8', 'ray_x-9', 'ray_y-10', 'ray_z-11', 'eot-12', 'cd-13', 'rad-14', 'f_sin-15', 'f_cos-16', 'fx-17', 'fy-18', 'fz-19', 'fx_norm-20', 'fy_norm-21', 'fz_norm-22', 'intrinsic-23', 'extrinsic-24', 'azimuth-25', 'elevation-26', 'extrinsic_inv-27', 'g-28']
Selected features :  [12]
1. input_col =  [6, 7, 8, 26, 25]
2. gt_col =  [0, 1, 2]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.65s/it]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.65s/it]
===============================Dataset shape===============================
Mixed : (7000,)
===========================================================================
Mixed:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]
===============================Dataset shape===============================
Mixed : (2500,)
===========================================================================
===>No model ckpt
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - flag #######
Flag_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(4, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
  (sigmoid): Sigmoid()
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 4])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 4])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([1, 32])
mlp.seq1.6.bias torch.Size([1])
####### Model - height #######
Height_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(5, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (attention): Self_Attention(
    (softmax): Softmax(dim=-1)
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=2, bias=True)
    )
  )
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 5])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 5])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
attention.gamma torch.Size([1])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([2, 32])
mlp.seq1.6.bias torch.Size([2])
####### Model - refinement #######
Refinement_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(3, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (attention): Self_Attention(
    (softmax): Softmax(dim=-1)
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 3])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 3])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
attention.gamma torch.Size([1])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([3, 32])
mlp.seq1.6.bias torch.Size([3])
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate :  0.001
===> [Minibatch 1/13].........
torch.Size([512, 90, 1]) torch.Size([512, 90, 2])
torch.Size([512, 193, 1]) torch.Size([512, 193, 2])
   [##] Training... Training Loss : 113.115
   ======> Trajectory Loss : 80.813, Gravity Loss : 0.036, BelowGnd Loss : 0.000, Flag Loss : 1.358, Reprojection Loss : 30.908
   [##] Validating... Validating Loss : 116.496
   ======> Trajectory Loss : 90.531, Gravity Loss : 0.036, BelowGnd Loss : 0.000, Flag Loss : 1.356, Reprojection Loss : 24.572
===> [Minibatch 2/13].........
torch.Size([512, 95, 1]) torch.Size([512, 95, 2])
torch.Size([512, 193, 1]) torch.Size([512, 193, 2])
   [##] Training... Training Loss : 110.217
   ======> Trajectory Loss : 84.422, Gravity Loss : 0.035, BelowGnd Loss : 0.000, Flag Loss : 1.356, Reprojection Loss : 24.404
   [##] Validating... Validating Loss : 109.521
   ======> Trajectory Loss : 88.680, Gravity Loss : 0.036, BelowGnd Loss : 0.000, Flag Loss : 1.354, Reprojection Loss : 19.451
===> [Minibatch 3/13].........
