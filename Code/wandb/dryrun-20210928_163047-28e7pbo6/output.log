===============================================Features===============================================
Prediction = height, Environment = unity
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'intr_x-6', 'intr_y-7', 'intr_z-8', 'ray_x-9', 'ray_y-10', 'ray_z-11', 'eot-12', 'cd-13', 'rad-14', 'f_sin-15', 'f_cos-16', 'fx-17', 'fy-18', 'fz-19', 'fx_norm-20', 'fy_norm-21', 'fz_norm-22', 'intrinsic-23', 'extrinsic-24', 'azimuth-25', 'elevation-26', 'extrinsic_inv-27', 'g-28']
Selected features :  [12]
1. input_col =  [6, 7, 8, 26, 25]
2. gt_col =  [0, 1, 2]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.65s/it]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.65s/it]
===============================Dataset shape===============================
Mixed : (7000,)
===========================================================================
Mixed:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]
===============================Dataset shape===============================
Mixed : (2500,)
===========================================================================
===>No model ckpt
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - flag #######
Flag_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(4, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
  (sigmoid): Sigmoid()
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 4])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 4])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([1, 32])
mlp.seq1.6.bias torch.Size([1])
####### Model - height #######
Height_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(5, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (attention): Self_Attention(
    (softmax): Softmax(dim=-1)
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 5])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 5])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
attention.gamma torch.Size([1])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([1, 32])
mlp.seq1.6.bias torch.Size([1])
####### Model - refinement #######
Refinement_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(3, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (attention): Self_Attention(
    (softmax): Softmax(dim=-1)
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 3])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 3])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
attention.gamma torch.Size([1])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([3, 32])
mlp.seq1.6.bias torch.Size([3])
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate :  0.001
===> [Minibatch 1/13].........
tensor([[[-1.4335e-02,  4.7379e-01, -1.9666e-01,  ...,  1.5537e-02,
           4.1329e-02,  4.1897e-02],
         [ 4.2966e-02,  3.7473e-01, -1.1462e-01,  ..., -1.2316e-02,
           1.7945e-02,  5.4066e-02],
         [ 5.5815e-02,  2.2252e-01, -4.2234e-02,  ..., -2.9634e-02,
          -6.5301e-04,  6.1072e-02],
         ...,
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3824e-02,  4.7120e-01, -1.9405e-01,  ...,  1.3858e-02,
           3.1837e-02,  4.9801e-02],
         [ 4.4755e-02,  3.7523e-01, -1.1344e-01,  ..., -1.7997e-02,
           1.1572e-02,  6.3418e-02],
         [ 5.6906e-02,  2.2297e-01, -4.1291e-02,  ..., -3.5122e-02,
          -4.5296e-03,  6.9041e-02],
         ...,
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3888e-02,  4.7352e-01, -1.9651e-01,  ...,  1.8167e-02,
           5.6096e-02,  4.0761e-02],
         [ 4.5362e-02,  3.7430e-01, -1.1183e-01,  ..., -8.3195e-03,
           3.5372e-02,  5.1678e-02],
         [ 5.9962e-02,  2.2336e-01, -3.7787e-02,  ..., -2.5384e-02,
           1.8621e-02,  5.7867e-02],
         ...,
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        ...,

        [[-1.5199e-02,  4.7393e-01, -1.9790e-01,  ...,  1.1792e-02,
           1.4832e-02,  4.6131e-02],
         [ 3.8488e-02,  3.7545e-01, -1.2158e-01,  ..., -1.8485e-02,
          -1.3106e-02,  6.1594e-02],
         [ 4.6929e-02,  2.2251e-01, -5.2438e-02,  ..., -3.5769e-02,
          -3.2674e-02,  7.0947e-02],
         ...,
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3844e-02,  4.7146e-01, -1.9406e-01,  ...,  1.4259e-02,
           3.3816e-02,  4.9705e-02],
         [ 4.4469e-02,  3.7528e-01, -1.1338e-01,  ..., -1.7143e-02,
           1.4242e-02,  6.3404e-02],
         [ 5.6980e-02,  2.2324e-01, -4.1174e-02,  ..., -3.4200e-02,
          -5.2655e-04,  6.9272e-02],
         ...,
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3797e-02,  4.7138e-01, -1.9383e-01,  ...,  1.4349e-02,
           3.3187e-02,  5.0000e-02],
         [ 4.5319e-02,  3.7580e-01, -1.1347e-01,  ..., -1.7333e-02,
           1.3678e-02,  6.4002e-02],
         [ 5.8170e-02,  2.2419e-01, -4.0051e-02,  ..., -3.4395e-02,
          -6.7636e-04,  6.8856e-02],
         ...,
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]]], device='cuda:0', grad_fn=<ViewBackward>)
tensor([[[-1.4335e-02,  4.2966e-02,  5.5815e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.7379e-01,  3.7473e-01,  2.2252e-01,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.9666e-01, -1.1462e-01, -4.2234e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         ...,
         [ 1.5537e-02, -1.2316e-02, -2.9634e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.1329e-02,  1.7945e-02, -6.5301e-04,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.1897e-02,  5.4066e-02,  6.1072e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3824e-02,  4.4755e-02,  5.6906e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.7120e-01,  3.7523e-01,  2.2297e-01,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.9405e-01, -1.1344e-01, -4.1291e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         ...,
         [ 1.3858e-02, -1.7997e-02, -3.5122e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 3.1837e-02,  1.1572e-02, -4.5296e-03,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.9801e-02,  6.3418e-02,  6.9041e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3888e-02,  4.5362e-02,  5.9962e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.7352e-01,  3.7430e-01,  2.2336e-01,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.9651e-01, -1.1183e-01, -3.7787e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         ...,
         [ 1.8167e-02, -8.3195e-03, -2.5384e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 5.6096e-02,  3.5372e-02,  1.8621e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.0761e-02,  5.1678e-02,  5.7867e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        ...,

        [[-1.5199e-02,  3.8488e-02,  4.6929e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.7393e-01,  3.7545e-01,  2.2251e-01,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.9790e-01, -1.2158e-01, -5.2438e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         ...,
         [ 1.1792e-02, -1.8485e-02, -3.5769e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 1.4832e-02, -1.3106e-02, -3.2674e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.6131e-02,  6.1594e-02,  7.0947e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3844e-02,  4.4469e-02,  5.6980e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.7146e-01,  3.7528e-01,  2.2324e-01,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.9406e-01, -1.1338e-01, -4.1174e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         ...,
         [ 1.4259e-02, -1.7143e-02, -3.4200e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 3.3816e-02,  1.4242e-02, -5.2655e-04,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.9705e-02,  6.3404e-02,  6.9272e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]],

        [[-1.3797e-02,  4.5319e-02,  5.8170e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 4.7138e-01,  3.7580e-01,  2.2419e-01,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [-1.9383e-01, -1.1347e-01, -4.0051e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         ...,
         [ 1.4349e-02, -1.7333e-02, -3.4395e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 3.3187e-02,  1.3678e-02, -6.7636e-04,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03],
         [ 5.0000e-02,  6.4002e-02,  6.8856e-02,  ..., -1.0000e+03,
          -1.0000e+03, -1.0000e+03]]], device='cuda:0',
       grad_fn=<PermuteBackward>)
