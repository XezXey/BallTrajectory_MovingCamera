===============================================Features===============================================
Prediction = height, Environment = unity
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'intr_x-6', 'intr_y-7', 'intr_z-8', 'ray_x-9', 'ray_y-10', 'ray_z-11', 'eot-12', 'cd-13', 'rad-14', 'f_sin-15', 'f_cos-16', 'fx-17', 'fy-18', 'fz-19', 'fx_norm-20', 'fy_norm-21', 'fz_norm-22', 'intrinsic-23', 'extrinsic-24', 'azimuth-25', 'elevation-26', 'extrinsic_inv-27', 'g-28']
Selected features :  [12]
1. input_col =  [6, 7, 8, 26, 25]
2. gt_col =  [0, 1, 2]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.68s/it]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.68s/it]
===============================Dataset shape===============================
Mixed : (7000,)
===========================================================================
Mixed:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.58it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.58it/s]
===============================Dataset shape===============================
Mixed : (2500,)
===========================================================================
===>No model ckpt
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - flag #######
Flag_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(4, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
  (sigmoid): Sigmoid()
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 4])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 4])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([1, 32])
mlp.seq1.6.bias torch.Size([1])
####### Model - height #######
Height_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(5, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (attn): Self_Attention(
    (softmax): Softmax(dim=-1)
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=1, bias=True)
    )
  )
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 5])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 5])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([1, 32])
mlp.seq1.6.bias torch.Size([1])
####### Model - refinement #######
Refinement_Module(
  (rnn): Trainable_LSTM(
    (ls): Sequential(
      (0): LSTM(3, 64, batch_first=True, bidirectional=True)
      (1): LSTM(128, 64, batch_first=True, bidirectional=True)
      (2): LSTM(128, 64, batch_first=True, bidirectional=True)
    )
  )
  (mlp): Vanilla_MLP(
    (activation): LeakyReLU(negative_slope=0.01)
    (seq1): Sequential(
      (0): Linear(in_features=128, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): LeakyReLU(negative_slope=0.01)
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
rnn.h torch.Size([3, 2, 1, 64])
rnn.c torch.Size([3, 2, 1, 64])
rnn.ls.0.weight_ih_l0 torch.Size([256, 3])
rnn.ls.0.weight_hh_l0 torch.Size([256, 64])
rnn.ls.0.bias_ih_l0 torch.Size([256])
rnn.ls.0.bias_hh_l0 torch.Size([256])
rnn.ls.0.weight_ih_l0_reverse torch.Size([256, 3])
rnn.ls.0.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.0.bias_ih_l0_reverse torch.Size([256])
rnn.ls.0.bias_hh_l0_reverse torch.Size([256])
rnn.ls.1.weight_ih_l0 torch.Size([256, 128])
rnn.ls.1.weight_hh_l0 torch.Size([256, 64])
rnn.ls.1.bias_ih_l0 torch.Size([256])
rnn.ls.1.bias_hh_l0 torch.Size([256])
rnn.ls.1.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.1.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.1.bias_ih_l0_reverse torch.Size([256])
rnn.ls.1.bias_hh_l0_reverse torch.Size([256])
rnn.ls.2.weight_ih_l0 torch.Size([256, 128])
rnn.ls.2.weight_hh_l0 torch.Size([256, 64])
rnn.ls.2.bias_ih_l0 torch.Size([256])
rnn.ls.2.bias_hh_l0 torch.Size([256])
rnn.ls.2.weight_ih_l0_reverse torch.Size([256, 128])
rnn.ls.2.weight_hh_l0_reverse torch.Size([256, 64])
rnn.ls.2.bias_ih_l0_reverse torch.Size([256])
rnn.ls.2.bias_hh_l0_reverse torch.Size([256])
mlp.seq1.0.weight torch.Size([32, 128])
mlp.seq1.0.bias torch.Size([32])
mlp.seq1.2.weight torch.Size([32, 32])
mlp.seq1.2.bias torch.Size([32])
mlp.seq1.4.weight torch.Size([32, 32])
mlp.seq1.4.bias torch.Size([32])
mlp.seq1.6.weight torch.Size([3, 32])
mlp.seq1.6.bias torch.Size([3])
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate :  0.001
===> [Minibatch 1/13].........
torch.Size([512, 64, 128])
torch.Size([512, 128, 64])
torch.Size([512, 64, 64])
torch.Size([512, 64, 64])
torch.Size([512, 64, 128])
Traceback (most recent call last):
  File "train.py", line 357, in <module>
    epoch=epoch)
  File "train.py", line 148, in train
    pred_dict_train, in_train = utils_model.fw_pass(model_dict, input_dict=input_dict_train, cam_dict=cam_dict_train, gt_dict=gt_dict_train, latent_dict=latent_dict_train)
  File "/home/puntawat/Mint/Work/Vision/BallTrajectory_MovingCamera/Code/utils/utils_model.py", line 142, in fw_pass
    pred_h, _ = model_dict['height'](in_f=in_f, lengths=input_dict['lengths']-1 if (i_s == 'dt' and o_s == 'dt') else input_dict['lengths'])
  File "/home/puntawat/Mint/Work/Vision/working_environment/ball_venv3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/puntawat/Mint/Work/Vision/BallTrajectory_MovingCamera/Code/models/height_module.py", line 26, in forward
    out1 = self.attn(out1)
  File "/home/puntawat/Mint/Work/Vision/working_environment/ball_venv3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/puntawat/Mint/Work/Vision/BallTrajectory_MovingCamera/Code/models/self_attention.py", line 35, in forward
    assert False
AssertionError
